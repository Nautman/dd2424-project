/Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev
  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages/torchvision/image.so
  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Epoch 0/24
----------
/Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
train Loss: 0.2164 Acc: 0.9146
val Loss: 0.1578 Acc: 0.9418
Epoch 1/24
----------
train Loss: 0.1108 Acc: 0.9569
val Loss: 0.6730 Acc: 0.7179
Epoch 2/24
----------
train Loss: 0.0866 Acc: 0.9646
val Loss: 0.1117 Acc: 0.9547
Epoch 3/24
----------
train Loss: 0.0727 Acc: 0.9737
val Loss: 0.2970 Acc: 0.8762
Epoch 4/24
----------
train Loss: 0.0652 Acc: 0.9756
val Loss: 0.1150 Acc: 0.9553
Epoch 5/24
----------
train Loss: 0.0386 Acc: 0.9847
val Loss: 0.1442 Acc: 0.9493
Epoch 6/24
----------
train Loss: 0.0466 Acc: 0.9816
val Loss: 0.2597 Acc: 0.9134
Epoch 7/24
----------
train Loss: 0.0354 Acc: 0.9870
val Loss: 0.1404 Acc: 0.9560
Epoch 8/24
----------
train Loss: 0.0409 Acc: 0.9859
val Loss: 0.2139 Acc: 0.9114
Epoch 9/24
----------
train Loss: 0.0354 Acc: 0.9888
val Loss: 0.2144 Acc: 0.9378
Epoch 10/24
----------
train Loss: 0.0334 Acc: 0.9882
val Loss: 0.1462 Acc: 0.9520
Epoch 11/24
----------
train Loss: 0.0313 Acc: 0.9888
val Loss: 0.1408 Acc: 0.9479
Epoch 12/24
----------
train Loss: 0.0365 Acc: 0.9876
val Loss: 0.1151 Acc: 0.9594
Epoch 13/24
----------
train Loss: 0.0165 Acc: 0.9936
val Loss: 0.2070 Acc: 0.9465
Epoch 14/24
----------
train Loss: 0.0192 Acc: 0.9927
val Loss: 0.1509 Acc: 0.9587
Epoch 15/24
----------
train Loss: 0.0180 Acc: 0.9938
val Loss: 0.1246 Acc: 0.9628
Epoch 16/24
----------
train Loss: 0.0071 Acc: 0.9977
val Loss: 0.2247 Acc: 0.9614
Epoch 17/24
----------
train Loss: 0.0332 Acc: 0.9894
val Loss: 0.1368 Acc: 0.9567
Epoch 18/24
----------
train Loss: 0.0130 Acc: 0.9961
val Loss: 0.1944 Acc: 0.9459
Epoch 19/24
----------
train Loss: 0.0071 Acc: 0.9979
val Loss: 0.1392 Acc: 0.9682
Epoch 20/24
----------
train Loss: 0.0159 Acc: 0.9942
val Loss: 0.1704 Acc: 0.9533
Epoch 21/24
----------
train Loss: 0.0281 Acc: 0.9905
val Loss: 0.1861 Acc: 0.9378
Epoch 22/24
----------
train Loss: 0.0207 Acc: 0.9930
val Loss: 0.1540 Acc: 0.9486
Epoch 23/24
----------
train Loss: 0.0082 Acc: 0.9975
val Loss: 0.1925 Acc: 0.9465
Epoch 24/24
----------
train Loss: 0.0262 Acc: 0.9915
val Loss: 0.2445 Acc: 0.9134
Training complete in 44m 3s
Best val Acc: 0.968200