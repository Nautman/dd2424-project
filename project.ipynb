{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (2.2.0.post100)\n",
      "Requirement already satisfied: torchvision in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (0.15.2a0)\n",
      "Requirement already satisfied: filelock in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from requests->torchvision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from requests->torchvision) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms \n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from tempfile import TemporaryDirectory\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import os, time\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\n",
    "from torchvision.models import efficientnet_v2_m, EfficientNet_V2_M_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data, weights_path, device_type='cpu'):\n",
    "    if torch.cuda.is_available():\n",
    "        device_type = 'cuda:0'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device_type = 'mps'\n",
    "\n",
    "    device = torch.device(device_type)\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "    model = model.to(device)\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_data:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += torch.sum(predicted == labels.data)\n",
    "        print('Time taken:', time.time() - start)\n",
    "        print(f'Accuracy of the network on the test images: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, suffix, parameters, scheduler=0, num_epochs=25, device_type='cpu'):\n",
    "    if torch.cuda.is_available():\n",
    "        device_type = 'cuda:0'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device_type = 'mps'\n",
    "\n",
    "    device = torch.device(device_type)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    losses = {'train': [], 'val': []}\n",
    "    accuracies = {'train': [], 'val': []}\n",
    "\n",
    "    # Create a directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(\"./\", suffix + '.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                model.train() if phase == 'train' else model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                print('phase:', phase)\n",
    "                \n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs) # forward pass\n",
    "\n",
    "                        # outputs is probability of each class\n",
    "                        # labels needs to be probability of each class\n",
    "\n",
    "                        # we need the one-hot for the labels to get the loss\n",
    "                        true_outputs = torch.nn.functional.one_hot(labels, num_classes=37).float()\n",
    "\n",
    "                        # create preds by thresholding outputs\n",
    "                        loss = criterion(outputs, true_outputs)\n",
    "\n",
    "                        preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "                losses[phase].append(epoch_loss)\n",
    "                accuracies[phase].append(epoch_acc)\n",
    "                \n",
    "                outputstr = f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}'\n",
    "                print(outputstr)\n",
    "                # f.write(outputstr + '\\n')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "            print('epoch took:', time.time() - start)\n",
    "            start = time.time()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return best_model_params_path, best_acc, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "def get_transforms(conf):\n",
    "    base_transforms = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "    training_transforms = []\n",
    "\n",
    "    crop = conf.get('crop', False)\n",
    "    random_flip = conf.get('random_flip', False)\n",
    "    rotate_angle = conf.get('rotate_angle', 0)\n",
    "    random_resized_crop = conf.get('random_resized_crop', False)\n",
    "\n",
    "    if random_resized_crop:\n",
    "        training_transforms.append(transforms.RandomResizedCrop(224))\n",
    "    elif crop:\n",
    "        base_transforms.append(transforms.Resize(256))\n",
    "        base_transforms.append(transforms.CenterCrop(224))\n",
    "    else:\n",
    "        base_transforms.append(transforms.Resize((224, 224)))\n",
    "    \n",
    "    if random_flip:\n",
    "        training_transforms.append(transforms.RandomHorizontalFlip())\n",
    "    if rotate_angle != 0:\n",
    "        training_transforms.append(transforms.RandomRotation(rotate_angle))\n",
    "    \n",
    "    return base_transforms, training_transforms\n",
    "\n",
    "def train_test_val_split(base_transforms, training_transforms, split_indices):\n",
    "    train_dataset=OxfordIIITPet(root=\"./\", download=True, target_types='category', transform=transforms.Compose(base_transforms + training_transforms))\n",
    "    val_dataset=OxfordIIITPet(root=\"./\", download=True, target_types='category', transform=transforms.Compose(base_transforms))\n",
    "    test_dataset=OxfordIIITPet(root=\"./\", download=True, target_types='category', transform=transforms.Compose(base_transforms))\n",
    "\n",
    "    train_dataset = Subset(train_dataset, split_indices['train'])\n",
    "    val_dataset = Subset(val_dataset, split_indices['val'])\n",
    "    test_dataset = Subset(test_dataset, split_indices['test'])\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "def get_split_indices(dataset=OxfordIIITPet(root=\"./\", download=True, target_types='category'), train_split=0.7, val_split=0.2, seed=None):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_size = int(train_split * dataset_size)\n",
    "    val_size = int(val_split * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "    \n",
    "    # Split indices\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "    \n",
    "    # Save the indices for reuse\n",
    "    split_indices = {\n",
    "        'train': train_indices,\n",
    "        'val': val_indices,\n",
    "        'test': test_indices\n",
    "    }\n",
    "    \n",
    "    return split_indices\n",
    "\n",
    "def generate_datasets(\n",
    "        conf, split_indices\n",
    "    ):\n",
    "\n",
    "    base_transforms, training_transforms = get_transforms(conf)\n",
    "    train_dataset, val_dataset, test_dataset = train_test_val_split(base_transforms, training_transforms, split_indices)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "        'test': torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True),\n",
    "        'val': torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True),\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        'train': len(train_dataset),\n",
    "        'test': len(test_dataset),\n",
    "        'val': len(val_dataset),\n",
    "    }\n",
    "\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_resnet(resnet_size = \"18\"):\n",
    "    if resnet_size == \"18\":\n",
    "        resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    elif resnet_size == \"50\":\n",
    "        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    \n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    print(resnet.fc)\n",
    "\n",
    "    #resnet fc input size\n",
    "    input_size = resnet.fc.in_features\n",
    "\n",
    "    resnet.fc = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(input_size, 256),\n",
    "        nn.ReLU(),\n",
    "        # nn.Dropout(0.2),\n",
    "        nn.Linear(256, 37),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "\n",
    "    return resnet\n",
    "\n",
    "def multiclass_efficientnet(name = \"efficientnet_b4\"):\n",
    "    if name == \"efficientnet_b4\":\n",
    "        efficientnet = efficientnet_b4(weights=EfficientNet_B4_Weights.DEFAULT)\n",
    "    elif name == \"efficientnet_v2_m\":\n",
    "        efficientnet = efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n",
    "    \n",
    "    for param in efficientnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    print(efficientnet.classifier)\n",
    "\n",
    "    #efficientnet fc input size\n",
    "    input_size = efficientnet.classifier[1].in_features\n",
    "\n",
    "    efficientnet.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(input_size, 256),\n",
    "        nn.ReLU(),\n",
    "        # nn.Dropout(0.2),\n",
    "        nn.Linear(256, 37),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "\n",
    "    return efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_suffix(\n",
    "        conf,\n",
    "    ):\n",
    "    device_type = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        device_type = 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device_type = 'mps'\n",
    "    \n",
    "    suffix = \"\"\n",
    "    for key, value in conf.items():\n",
    "        suffix += key + ':' + str(value) + ';'\n",
    "    suffix += device_type\n",
    "\n",
    "    return suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'efficientnet_v2_m'\n",
    "random_flip = False\n",
    "rotate_angle = 0\n",
    "crop = False\n",
    "random_resized_crop = 1\n",
    "\n",
    "base_conf = {\n",
    "    'model_name': model_name,\n",
    "    'crop': crop,\n",
    "    'random_flip': random_flip,\n",
    "    'rotate_angle': rotate_angle,\n",
    "    'scale': random_resized_crop\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == 'resnet18':\n",
    "        return multiclass_resnet(\"18\")\n",
    "    elif model_name == 'resnet50':\n",
    "        return multiclass_resnet(\"50\")\n",
    "    elif model_name == 'efficientnet_b4':\n",
    "        return multiclass_efficientnet(model_name)\n",
    "    elif model_name == 'efficientnet_v2_m':\n",
    "        return multiclass_efficientnet(model_name)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)]\n",
      "[]\n",
      "[ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)]\n"
     ]
    }
   ],
   "source": [
    "base_transforms, training_transforms = get_transforms(base_conf)\n",
    "print(base_transforms)\n",
    "print(training_transforms)\n",
    "print(base_transforms + training_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.3, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "model_name:efficientnet_v2_m;crop:False;random_flip:False;rotate_angle:0;random_resized_crop:False;mps\n",
      "Epoch 0/4\n",
      "----------\n",
      "phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/douglas/anaconda3/envs/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 3.3646 Acc: 0.4057\n",
      "phase: val\n",
      "val Loss: 3.0983 Acc: 0.6168\n",
      "epoch took: 78.92533302307129\n",
      "Epoch 1/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 3.0302 Acc: 0.6630\n",
      "phase: val\n",
      "val Loss: 2.9649 Acc: 0.7283\n",
      "epoch took: 85.622318983078\n",
      "Epoch 2/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.9365 Acc: 0.7519\n",
      "phase: val\n",
      "val Loss: 2.9276 Acc: 0.7609\n",
      "epoch took: 117.4213137626648\n",
      "Epoch 3/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8954 Acc: 0.7865\n",
      "phase: val\n",
      "val Loss: 2.9104 Acc: 0.7772\n",
      "epoch took: 114.56469917297363\n",
      "Epoch 4/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8666 Acc: 0.8121\n",
      "phase: val\n",
      "val Loss: 2.9030 Acc: 0.7622\n",
      "epoch took: 117.75068998336792\n",
      "Training complete in 8m 35s\n",
      "Best val Acc: 0.777174\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.3, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "model_name:efficientnet_v2_m;crop:True;random_flip:False;rotate_angle:0;random_resized_crop:False;mps\n",
      "Epoch 0/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 3.2972 Acc: 0.4724\n",
      "phase: val\n",
      "val Loss: 3.0349 Acc: 0.6739\n",
      "epoch took: 119.68500089645386\n",
      "Epoch 1/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.9540 Acc: 0.7376\n",
      "phase: val\n",
      "val Loss: 2.9471 Acc: 0.7337\n",
      "epoch took: 121.63792681694031\n",
      "Epoch 2/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8851 Acc: 0.8009\n",
      "phase: val\n",
      "val Loss: 2.8971 Acc: 0.7867\n",
      "epoch took: 128.2208287715912\n",
      "Epoch 3/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8526 Acc: 0.8222\n",
      "phase: val\n",
      "val Loss: 2.8735 Acc: 0.8030\n",
      "epoch took: 126.69382214546204\n",
      "Epoch 4/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8431 Acc: 0.8273\n",
      "phase: val\n",
      "val Loss: 2.8738 Acc: 0.7976\n",
      "epoch took: 129.6922209262848\n",
      "Training complete in 10m 27s\n",
      "Best val Acc: 0.802989\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.3, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "model_name:efficientnet_v2_m;crop:False;random_flip:True;rotate_angle:0;random_resized_crop:False;mps\n",
      "Epoch 0/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 3.3569 Acc: 0.4185\n",
      "phase: val\n",
      "val Loss: 3.0914 Acc: 0.6399\n",
      "epoch took: 127.38400602340698\n",
      "Epoch 1/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.9713 Acc: 0.7442\n",
      "phase: val\n",
      "val Loss: 2.9347 Acc: 0.7731\n",
      "epoch took: 115.63227915763855\n",
      "Epoch 2/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8848 Acc: 0.8012\n",
      "phase: val\n",
      "val Loss: 2.8857 Acc: 0.8030\n",
      "epoch took: 91.8637068271637\n",
      "Epoch 3/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8549 Acc: 0.8253\n",
      "phase: val\n",
      "val Loss: 2.8761 Acc: 0.8111\n",
      "epoch took: 95.23461985588074\n",
      "Epoch 4/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8409 Acc: 0.8385\n",
      "phase: val\n",
      "val Loss: 2.8629 Acc: 0.8125\n",
      "epoch took: 99.80412697792053\n",
      "Training complete in 8m 51s\n",
      "Best val Acc: 0.812500\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.3, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "model_name:efficientnet_v2_m;crop:False;random_flip:False;rotate_angle:45;random_resized_crop:False;mps\n",
      "Epoch 0/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 3.3852 Acc: 0.3870\n",
      "phase: val\n",
      "val Loss: 3.1009 Acc: 0.6372\n",
      "epoch took: 131.4508740901947\n",
      "Epoch 1/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 3.0117 Acc: 0.6949\n",
      "phase: val\n",
      "val Loss: 2.9359 Acc: 0.7527\n",
      "epoch took: 160.95891690254211\n",
      "Epoch 2/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.9372 Acc: 0.7488\n",
      "phase: val\n",
      "val Loss: 2.9232 Acc: 0.7568\n",
      "epoch took: 149.94015192985535\n",
      "Epoch 3/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.9232 Acc: 0.7512\n",
      "phase: val\n",
      "val Loss: 2.9018 Acc: 0.7826\n",
      "epoch took: 137.76671624183655\n",
      "Epoch 4/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.9106 Acc: 0.7655\n",
      "phase: val\n",
      "val Loss: 2.8905 Acc: 0.7812\n",
      "epoch took: 145.18285083770752\n",
      "Training complete in 12m 6s\n",
      "Best val Acc: 0.782609\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.3, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "model_name:efficientnet_v2_m;crop:False;random_flip:False;rotate_angle:0;random_resized_crop:False;mps\n",
      "Epoch 0/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 3.3406 Acc: 0.4523\n",
      "phase: val\n",
      "val Loss: 3.0293 Acc: 0.7201\n",
      "epoch took: 102.33364701271057\n",
      "Epoch 1/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.9484 Acc: 0.7632\n",
      "phase: val\n",
      "val Loss: 2.9107 Acc: 0.7948\n",
      "epoch took: 100.40567922592163\n",
      "Epoch 2/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8803 Acc: 0.8055\n",
      "phase: val\n",
      "val Loss: 2.8861 Acc: 0.7935\n",
      "epoch took: 98.96240210533142\n",
      "Epoch 3/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8485 Acc: 0.8319\n",
      "phase: val\n",
      "val Loss: 2.8595 Acc: 0.8234\n",
      "epoch took: 105.15238308906555\n",
      "Epoch 4/4\n",
      "----------\n",
      "phase: train\n",
      "train Loss: 2.8289 Acc: 0.8529\n",
      "phase: val\n",
      "val Loss: 2.8542 Acc: 0.8247\n",
      "epoch took: 102.55983781814575\n",
      "Training complete in 8m 30s\n",
      "Best val Acc: 0.824728\n",
      "[('./model_name:efficientnet_v2_m;crop:False;random_flip:False;rotate_angle:0;random_resized_crop:False;mps.pt', tensor(0.7772, device='mps:0')), ('./model_name:efficientnet_v2_m;crop:True;random_flip:False;rotate_angle:0;random_resized_crop:False;mps.pt', tensor(0.8030, device='mps:0')), ('./model_name:efficientnet_v2_m;crop:False;random_flip:True;rotate_angle:0;random_resized_crop:False;mps.pt', tensor(0.8125, device='mps:0')), ('./model_name:efficientnet_v2_m;crop:False;random_flip:False;rotate_angle:45;random_resized_crop:False;mps.pt', tensor(0.7826, device='mps:0')), ('./model_name:efficientnet_v2_m;crop:False;random_flip:False;rotate_angle:0;random_resized_crop:False;mps.pt', tensor(0.8247, device='mps:0'))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def generate_confs():\n",
    "    model_name = 'efficientnet_v2_m'\n",
    "    crops = ['off', 'center-crop', 'random-resized-crop']\n",
    "    random_flips = [True, False]\n",
    "    rotate_angles = [0, 30]\n",
    "\n",
    "    # Generate confs \n",
    "    # confs = [\n",
    "    #     {**base_conf, 'model_name': model}\n",
    "    #     for model in models\n",
    "    # ]\n",
    "    # confs = [\n",
    "    #     # crop and flip false\n",
    "    #     # baseline\n",
    "    #      {\n",
    "    #         'model_name': model_name,\n",
    "    #         'crop': False,\n",
    "    #         'random_flip': False,\n",
    "    #         'rotate_angle': 0,\n",
    "    #         'random_resized_crop': False,\n",
    "    #     },\n",
    "    # val Loss: 2.9030 Acc: 0.7622\n",
    "    # epoch took: 117.75068998336792\n",
    "    # Training complete in 8m 35s\n",
    "    # Best val Acc: 0.777174\n",
    "\n",
    "    #     # crop on\n",
    "    #     {\n",
    "    #         'model_name': model_name,\n",
    "    #         'crop': True,\n",
    "    #         'random_flip': False,\n",
    "    #         'rotate_angle': 0,\n",
    "    #         'random_resized_crop': False,\n",
    "    #     },\n",
    "    # val Loss: 2.8738 Acc: 0.7976\n",
    "    # epoch took: 129.6922209262848\n",
    "    # Training complete in 10m 27s\n",
    "    # Best val Acc: 0.802989\n",
    "\n",
    "    #     # flip on\n",
    "    #     {\n",
    "    #         'model_name': model_name,\n",
    "    #         'crop': False,\n",
    "    #         'random_flip': True,\n",
    "    #         'rotate_angle': 0,\n",
    "    #         'random_resized_crop': False,\n",
    "    #     },\n",
    "    # val Loss: 2.8629 Acc: 0.8125\n",
    "    # epoch took: 99.80412697792053\n",
    "    # Training complete in 8m 51s\n",
    "    # Best val Acc: 0.812500\n",
    "\n",
    "    #     # rotate 45\n",
    "    #     {\n",
    "    #         'model_name': model_name,\n",
    "    #         'crop': False,\n",
    "    #         'random_flip': False,\n",
    "    #         'rotate_angle': 45,\n",
    "    #         'random_resized_crop': False,\n",
    "    #     },\n",
    "    # val Loss: 2.8905 Acc: 0.7812\n",
    "    # epoch took: 145.18285083770752\n",
    "    # Training complete in 12m 6s\n",
    "    # Best val Acc: 0.782609\n",
    "\n",
    "    #     # random_resized_crop on\n",
    "    #     {\n",
    "    #         'model_name': model_name,\n",
    "    #         'crop': False,\n",
    "    #         'random_flip': False,\n",
    "    #         'rotate_angle': 0,\n",
    "    #         'random_resized_crop': False,\n",
    "    #     },\n",
    "    # ]\n",
    "\n",
    "    confs = []\n",
    "    for crop in crops:\n",
    "        for random_flip in random_flips:\n",
    "            for rotate_angle in rotate_angles:\n",
    "                conf = {\n",
    "                    'model_name': model_name,\n",
    "                    'crop': crop == 'center-crop',\n",
    "                    'random_flip': random_flip,\n",
    "                    'rotate_angle': rotate_angle,\n",
    "                    'random_resized_crop': crop == 'random-resized-crop',\n",
    "                }\n",
    "                confs.append(conf)\n",
    "\n",
    "    return confs\n",
    "\n",
    "split_indices = get_split_indices(seed=42)\n",
    "confs = generate_confs()\n",
    "\n",
    "weights_and_accs = []\n",
    "for conf in confs:\n",
    "    dataloaders, dataset_sizes = generate_datasets(conf, split_indices)\n",
    "    # print(dataloaders['train'].dataset)\n",
    "\n",
    "    # # print(dataloaders['train'].dataset)\n",
    "\n",
    "    model = get_model(conf['model_name'])\n",
    "    suffix = create_suffix(conf)\n",
    "    print(suffix)\n",
    "    parameters = model.fc.parameters() if conf['model_name'].startswith('resnet') else model.classifier.parameters()\n",
    "    weights_path, best_acc, losses, accuracies = train_model(model, dataloaders, dataset_sizes, suffix, parameters=parameters, num_epochs=5)\n",
    "    weights_and_accs.append((weights_path, best_acc))\n",
    "\n",
    "print(weights_and_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1] + [2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd2424-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
