{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms \n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from tempfile import TemporaryDirectory\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import os, time\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\n",
    "from torchvision.models import efficientnet_v2_m, EfficientNet_V2_M_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data, weights_path, device_type='cpu'):\n",
    "    if torch.cuda.is_available():\n",
    "        device_type = 'cuda:0'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device_type = 'mps'\n",
    "\n",
    "    device = torch.device(device_type)\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "    model = model.to(device)\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_data:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += torch.sum(predicted == labels.data)\n",
    "        print('Time taken:', time.time() - start)\n",
    "        print(f'Accuracy of the network on the test images: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, suffix, parameters, scheduler=0, num_epochs=25, device_type='cpu'):\n",
    "    if torch.cuda.is_available():\n",
    "        device_type = 'cuda:0'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device_type = 'mps'\n",
    "\n",
    "    device = torch.device(device_type)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    losses = {'train': [], 'val': []}\n",
    "    accuracies = {'train': [], 'val': []}\n",
    "\n",
    "    # Create a directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(\"./\", suffix + '.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                model.train() if phase == 'train' else model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                print('phase:', phase)\n",
    "                \n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs) # forward pass\n",
    "\n",
    "                        # outputs is probability of each class\n",
    "                        # labels needs to be probability of each class\n",
    "\n",
    "                        # we need the one-hot for the labels to get the loss\n",
    "                        true_outputs = torch.nn.functional.one_hot(labels, num_classes=37).float()\n",
    "\n",
    "                        # create preds by thresholding outputs\n",
    "                        loss = criterion(outputs, true_outputs)\n",
    "\n",
    "                        preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "                losses[phase].append(epoch_loss)\n",
    "                accuracies[phase].append(epoch_acc)\n",
    "                \n",
    "                outputstr = f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}'\n",
    "                print(outputstr)\n",
    "                # f.write(outputstr + '\\n')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "            print('epoch took:', time.time() - start)\n",
    "            start = time.time()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return best_model_params_path, best_acc, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "def get_transforms(conf):\n",
    "    base_transforms = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "    training_transforms = []\n",
    "\n",
    "    crop = conf.get('crop', False)\n",
    "    random_flip = conf.get('random_flip', False)\n",
    "    rotate_angle = conf.get('rotate_angle', 0)\n",
    "    random_resized_crop = conf.get('random_resized_crop', False)\n",
    "\n",
    "    if crop:\n",
    "        base_transforms.append(transforms.Resize(256))\n",
    "        base_transforms.append(transforms.CenterCrop(224))\n",
    "    else:\n",
    "        base_transforms.append(transforms.Resize(224))\n",
    "    \n",
    "    if random_flip:\n",
    "        training_transforms.append(transforms.RandomHorizontalFlip())\n",
    "    if rotate_angle != 0:\n",
    "        training_transforms.append(transforms.RandomRotation(rotate_angle))\n",
    "\n",
    "    if random_resized_crop:\n",
    "        training_transforms.append(transforms.RandomResizedCrop(224))\n",
    "    \n",
    "    return base_transforms, training_transforms\n",
    "\n",
    "def train_test_val_split(train_transforms, base_transforms, split_indices):\n",
    "    train_dataset=OxfordIIITPet(root=\"./\", download=True, target_types='category', transforms=transforms.Compose(train_transforms))\n",
    "    val_dataset=OxfordIIITPet(root=\"./\", download=True, target_types='category', transforms=transforms.Compose(base_transforms))\n",
    "    test_dataset=OxfordIIITPet(root=\"./\", download=True, target_types='category', transforms=transforms.Compose(base_transforms))\n",
    "\n",
    "    train_dataset = Subset(train_dataset, split_indices['train'])\n",
    "    val_dataset = Subset(val_dataset, split_indices['val'])\n",
    "    test_dataset = Subset(test_dataset, split_indices['test'])\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "def get_split_indices(dataset=OxfordIIITPet(root=\"./\", download=True, target_types='category'), train_split=0.7, val_split=0.2, seed=None):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_size = int(train_split * dataset_size)\n",
    "    val_size = int(val_split * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "    \n",
    "    # Split indices\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "    \n",
    "    # Save the indices for reuse\n",
    "    split_indices = {\n",
    "        'train': train_indices,\n",
    "        'val': val_indices,\n",
    "        'test': test_indices\n",
    "    }\n",
    "    \n",
    "    return split_indices\n",
    "\n",
    "def generate_datasets(\n",
    "        conf, split_indices\n",
    "    ):\n",
    "\n",
    "    train_transforms, training_transforms = get_transforms(conf)    \n",
    "    train_dataset, val_dataset, test_dataset = train_test_val_split(train_transforms, training_transforms, split_indices)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "        'test': torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True),\n",
    "        'val': torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True),\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        'train': len(train_dataset),\n",
    "        'test': len(test_dataset),\n",
    "        'val': len(val_dataset),\n",
    "    }\n",
    "\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_resnet(resnet_size = \"18\"):\n",
    "    if resnet_size == \"18\":\n",
    "        resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    elif resnet_size == \"50\":\n",
    "        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    \n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    print(resnet.fc)\n",
    "\n",
    "    #resnet fc input size\n",
    "    input_size = resnet.fc.in_features\n",
    "\n",
    "    resnet.fc = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(input_size, 256),\n",
    "        nn.ReLU(),\n",
    "        # nn.Dropout(0.2),\n",
    "        nn.Linear(256, 37),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "\n",
    "    return resnet\n",
    "\n",
    "def multiclass_efficientnet(name = \"efficientnet_b4\"):\n",
    "    if name == \"efficientnet_b4\":\n",
    "        efficientnet = efficientnet_b4(weights=EfficientNet_B4_Weights.DEFAULT)\n",
    "    elif name == \"efficientnet_v2_m\":\n",
    "        efficientnet = efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n",
    "    \n",
    "    for param in efficientnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    print(efficientnet.classifier)\n",
    "\n",
    "    #efficientnet fc input size\n",
    "    input_size = efficientnet.classifier[1].in_features\n",
    "\n",
    "    efficientnet.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(input_size, 256),\n",
    "        nn.ReLU(),\n",
    "        # nn.Dropout(0.2),\n",
    "        nn.Linear(256, 37),\n",
    "        nn.Softmax()\n",
    "    )\n",
    "\n",
    "    return efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_suffix(\n",
    "        conf,\n",
    "    ):\n",
    "    device_type = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        device_type = 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device_type = 'mps'\n",
    "    \n",
    "    suffix = \"\"\n",
    "    for key, value in conf.items():\n",
    "        suffix += key + str(value)\n",
    "    suffix += device_type\n",
    "\n",
    "    return suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'efficientnet_v2_m'\n",
    "random_flip = False\n",
    "rotate_angle = 0\n",
    "crop = False\n",
    "random_resized_crop = 1\n",
    "\n",
    "base_conf = {\n",
    "    'model_name': model_name,\n",
    "    'crop': crop,\n",
    "    'random_flip': random_flip,\n",
    "    'rotate_angle': rotate_angle,\n",
    "    'scale': random_resized_crop\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == 'resnet18':\n",
    "        return multiclass_resnet(\"18\")\n",
    "    elif model_name == 'resnet50':\n",
    "        return multiclass_resnet(\"50\")\n",
    "    elif model_name == 'efficientnet_b4':\n",
    "        return multiclass_efficientnet(model_name)\n",
    "    elif model_name == 'efficientnet_v2_m':\n",
    "        return multiclass_efficientnet(model_name)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_m-dc08266a.pth\" to /Users/daghjelm/.cache/torch/hub/checkpoints/efficientnet_v2_m-dc08266a.pth\n",
      "14.6%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conf \u001b[38;5;129;01min\u001b[39;00m confs:\n\u001b[1;32m     64\u001b[0m     dataloaders, dataset_sizes \u001b[38;5;241m=\u001b[39m generate_datasets(conf, split_indices)\n\u001b[0;32m---> 65\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     suffix \u001b[38;5;241m=\u001b[39m create_suffix(conf)\n\u001b[1;32m     67\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m conf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mparameters()\n",
      "Cell \u001b[0;32mIn[31], line 9\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m multiclass_efficientnet(model_name)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientnet_v2_m\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmulticlass_efficientnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 30\u001b[0m, in \u001b[0;36mmulticlass_efficientnet\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     28\u001b[0m     efficientnet \u001b[38;5;241m=\u001b[39m efficientnet_b4(weights\u001b[38;5;241m=\u001b[39mEfficientNet_B4_Weights\u001b[38;5;241m.\u001b[39mDEFAULT)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnet_v2_m\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     efficientnet \u001b[38;5;241m=\u001b[39m \u001b[43mefficientnet_v2_m\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEfficientNet_V2_M_Weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m efficientnet\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m     33\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages/torchvision/models/_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs\u001b[38;5;241m.\u001b[39mkeys()),\u001b[38;5;250m \u001b[39mseparate_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as positional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages/torchvision/models/_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[1;32m    226\u001b[0m     kwargs[weights_param] \u001b[38;5;241m=\u001b[39m default_weights_arg\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages/torchvision/models/efficientnet.py:1085\u001b[0m, in \u001b[0;36mefficientnet_v2_m\u001b[0;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m weights \u001b[38;5;241m=\u001b[39m EfficientNet_V2_M_Weights\u001b[38;5;241m.\u001b[39mverify(weights)\n\u001b[1;32m   1084\u001b[0m inverted_residual_setting, last_channel \u001b[38;5;241m=\u001b[39m _efficientnet_conf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnet_v2_m\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1085\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_efficientnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43minverted_residual_setting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNorm2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages/torchvision/models/efficientnet.py:360\u001b[0m, in \u001b[0;36m_efficientnet\u001b[0;34m(inverted_residual_setting, dropout, last_channel, weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m model \u001b[38;5;241m=\u001b[39m EfficientNet(inverted_residual_setting, dropout, last_channel\u001b[38;5;241m=\u001b[39mlast_channel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages/torchvision/models/_api.py:90\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages/torch/hub.py:766\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    764\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    765\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/site-packages/torch/hub.py:651\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mfile_size, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progress,\n\u001b[1;32m    649\u001b[0m           unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 651\u001b[0m         buffer \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    653\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dd2424-project/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generate_confs():\n",
    "    model_name = 'efficientnet_v2_m'\n",
    "    crops = [True, False]\n",
    "    random_flips = [True, False]\n",
    "    rotate_angles = [0, 90]\n",
    "\n",
    "    # Generate confs \n",
    "    # confs = [\n",
    "    #     {**base_conf, 'model_name': model}\n",
    "    #     for model in models\n",
    "    # ]\n",
    "    confs = [\n",
    "        # crop and flip false\n",
    "        # baseline\n",
    "         {\n",
    "            'model_name': model_name,\n",
    "            'crop': False,\n",
    "            'random_flip': False,\n",
    "            'rotate_angle': 0,\n",
    "            'random_resized_crop': False,\n",
    "        },\n",
    "        # crop on\n",
    "        {\n",
    "            'model_name': model_name,\n",
    "            'crop': True,\n",
    "            'random_flip': False,\n",
    "            'rotate_angle': 0,\n",
    "            'random_resized_crop': False,\n",
    "        },\n",
    "        # flip on\n",
    "        {\n",
    "            'model_name': model_name,\n",
    "            'crop': False,\n",
    "            'random_flip': True,\n",
    "            'rotate_angle': 0,\n",
    "            'random_resized_crop': False,\n",
    "        },\n",
    "        # rotate 45\n",
    "        {\n",
    "            'model_name': model_name,\n",
    "            'crop': False,\n",
    "            'random_flip': False,\n",
    "            'rotate_angle': 45,\n",
    "            'random_resized_crop': False,\n",
    "        },\n",
    "        # scale\n",
    "        {\n",
    "            'model_name': model_name,\n",
    "            'crop': False,\n",
    "            'random_flip': False,\n",
    "            'rotate_angle': 0,\n",
    "            'random_resized_crop': False,\n",
    "        },\n",
    "\n",
    "    ]\n",
    "\n",
    "    return confs\n",
    "\n",
    "split_indices = get_split_indices(seed=42)\n",
    "confs = generate_confs()\n",
    "\n",
    "weights_and_accs = []\n",
    "for conf in confs:\n",
    "    dataloaders, dataset_sizes = generate_datasets(conf, split_indices)\n",
    "    model = get_model(conf['model_name'])\n",
    "    suffix = create_suffix(conf)\n",
    "    parameters = model.fc.parameters() if conf['model_name'].startswith('resnet') else model.classifier.parameters()\n",
    "    weights_path, best_acc, losses, accuracies = train_model(model, dataloaders, dataset_sizes, suffix, parameters=parameters, num_epochs=5)\n",
    "    weights_and_accs.append((weights_path, best_acc))\n",
    "\n",
    "print(weights_and_accs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd2424-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
